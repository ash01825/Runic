{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-14T07:21:49.147192Z",
     "start_time": "2025-10-14T07:21:13.903127Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"Loading the sentence-transformer model 'all-MiniLM-L6-v2'...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Model loaded successfully.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the sentence-transformer model 'all-MiniLM-L6-v2'...\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T07:22:24.197692Z",
     "start_time": "2025-10-14T07:22:24.189793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_documents(path):\n",
    "    \"\"\"\n",
    "    Loads all .log, .json, .txt, and .md files from a directory.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    for root, _, files in os.walk(path):\n",
    "        for file_name in files:\n",
    "            # Only read file types we care about\n",
    "            if file_name.endswith(('.log', '.json', '.txt', '.md')):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        documents.append({\n",
    "                            'name': file_name,\n",
    "                            'path': file_path,\n",
    "                            'content': f.read()\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "    return documents\n",
    "\n",
    "print(\"\\nLoading all runbooks and logs from the '../data' directory...\")\n",
    "all_docs = load_documents('../data')\n",
    "doc_contents = [doc['content'] for doc in all_docs]\n",
    "print(f\"Successfully loaded {len(all_docs)} documents.\")\n"
   ],
   "id": "b032244d9a3d876b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading all runbooks and logs from the '../data' directory...\n",
      "Successfully loaded 12 documents.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T07:22:32.406178Z",
     "start_time": "2025-10-14T07:22:29.445725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nCreating embeddings for all documents... (This may take a moment)\")\n",
    "doc_embeddings = model.encode(doc_contents, convert_to_tensor=False)\n",
    "print(f\"Embeddings created successfully. Vector shape: {doc_embeddings.shape}\")\n"
   ],
   "id": "72109709062c4f1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating embeddings for all documents... (This may take a moment)\n",
      "Embeddings created successfully. Vector shape: (12, 384)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T07:22:46.633709Z",
     "start_time": "2025-10-14T07:22:46.630070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d = doc_embeddings.shape[1]\n",
    "\n",
    "print(\"\\nBuilding the FAISS index...\")\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(doc_embeddings)\n",
    "print(f\"FAISS index built. Total vectors in index: {index.ntotal}\")\n"
   ],
   "id": "cdeaef4ce865d749",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building the FAISS index...\n",
      "FAISS index built. Total vectors in index: 12\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T07:23:01.482532Z",
     "start_time": "2025-10-14T07:23:01.478668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search(query, k=3):\n",
    "    \"\"\"\n",
    "    Takes a text query, embeds it, and searches the FAISS index for the top k results.\n",
    "    \"\"\"\n",
    "    print(f\"\\n==============================================================\")\n",
    "    print(f\"Searching for top {k} documents matching query: '{query}'\")\n",
    "    print(f\"==============================================================\")\n",
    "\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    print(\"\\n--- Search Results ---\")\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        print(f\"\\n{i+1}. Document: {all_docs[idx]['name']} (Score/Distance: {distances[0][i]:.4f})\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(f\"{all_docs[idx]['content'][:450]}...\")"
   ],
   "id": "9ec86882df20c5a5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T07:23:31.470614Z",
     "start_time": "2025-10-14T07:23:30.235381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "search(\"The auth-service has high CPU usage and is exhausted\")\n",
    "\n",
    "search(\"I'm getting database connection timeouts and latency spikes from the payment gateway\")\n",
    "\n",
    "search(\"My search-engine service is in a crash loop after the last deployment and is unavailable\")"
   ],
   "id": "ab648044ca6c4a13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================\n",
      "Searching for top 3 documents matching query: 'The auth-service has high CPU usage and is exhausted'\n",
      "==============================================================\n",
      "\n",
      "--- Search Results ---\n",
      "\n",
      "1. Document: incident_001_cpu_spike.log (Score/Distance: 0.6258)\n",
      "--------------------------------------------------\n",
      "[ERROR] timestamp=1728879963 service=auth-service msg=\"High resource warning; triggering ResourceExhaustion event\" cpu_utilization=94.3% p99_latency_ms=2100 task_id=b4a2e1f-8c7d error=\"Request processing time exceeded 5000ms\"...\n",
      "\n",
      "2. Document: high_cpu_restart.md (Score/Distance: 0.9922)\n",
      "--------------------------------------------------\n",
      "# High CPU Restart Procedure\n",
      "\n",
      "## üîç Incident Symptoms\n",
      "- An incident is flagged as an anomaly with a score of **1.0**, indicating a `metricValue` (CPU Usage) of **> 90%**.\n",
      "- The `eventType` in the alert payload is `ResourceExhaustion`.\n",
      "- The `service` field identifies a specific component, like `auth-service`, as the source.\n",
      "- P99 latency for the service is significantly elevated.\n",
      "\n",
      "## üìà Possible Causes\n",
      "- **Stuck Process:** A worker thread or proces...\n",
      "\n",
      "3. Document: database_latency.md (Score/Distance: 1.2996)\n",
      "--------------------------------------------------\n",
      "# High Database Query Latency\n",
      "\n",
      "## üîç Incident Symptoms\n",
      "- The `eventType` is `LatencySpike` or `Timeouts`.\n",
      "- The `service` experiencing the issue is a database like `inventory-db`, or a service that depends on it.\n",
      "- Application-level metrics show a sharp increase in the duration of database transactions.\n",
      "- CloudWatch RDS metrics show high `DBLoad` and a low number of `FreeableMemory`.\n",
      "\n",
      "## üìà Possible Causes\n",
      "- **Inefficient Query:** A new or existing...\n",
      "\n",
      "==============================================================\n",
      "Searching for top 3 documents matching query: 'I'm getting database connection timeouts and latency spikes from the payment gateway'\n",
      "==============================================================\n",
      "\n",
      "--- Search Results ---\n",
      "\n",
      "1. Document: incident_003_latency.log (Score/Distance: 0.9396)\n",
      "--------------------------------------------------\n",
      "[WARN] timestamp=1728879975 service=payment-gateway msg=\"High DB query latency detected\" eventType=LatencySpike dependency=inventory-db p99_latency_ms=2105 threshold_ms=1000 query_signature=\"SELECT * FROM products WHERE...\"...\n",
      "\n",
      "2. Document: database_latency.md (Score/Distance: 1.0668)\n",
      "--------------------------------------------------\n",
      "# High Database Query Latency\n",
      "\n",
      "## üîç Incident Symptoms\n",
      "- The `eventType` is `LatencySpike` or `Timeouts`.\n",
      "- The `service` experiencing the issue is a database like `inventory-db`, or a service that depends on it.\n",
      "- Application-level metrics show a sharp increase in the duration of database transactions.\n",
      "- CloudWatch RDS metrics show high `DBLoad` and a low number of `FreeableMemory`.\n",
      "\n",
      "## üìà Possible Causes\n",
      "- **Inefficient Query:** A new or existing...\n",
      "\n",
      "3. Document: incident_005_dns_error.txt (Score/Distance: 1.2088)\n",
      "--------------------------------------------------\n",
      "Application startup failed for service: frontend-ui\n",
      "Timestamp: 2025-10-14T04:35:00Z\n",
      "Error: Could not establish connection to backend service.\n",
      "\n",
      "Caused by: java.net.UnknownHostException: payment-gateway.internal.opsflow.local: Temporary failure in name resolution\n",
      "    at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)\n",
      "    at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928)\n",
      "    at java.net.InetAddress.getAddressesFromNameServ...\n",
      "\n",
      "==============================================================\n",
      "Searching for top 3 documents matching query: 'My search-engine service is in a crash loop after the last deployment and is unavailable'\n",
      "==============================================================\n",
      "\n",
      "--- Search Results ---\n",
      "\n",
      "1. Document: service_crash_loop.md (Score/Distance: 0.9920)\n",
      "--------------------------------------------------\n",
      "# Service Crash Loop\n",
      "\n",
      "## üîç Incident Symptoms\n",
      "- The `eventType` is `ServiceDown`.\n",
      "- Monitoring systems (like Kubernetes or ECS) report that a service is restarting more than 5 times in 10 minutes.\n",
      "- The service is unreachable and returns 503 Service Unavailable errors.\n",
      "- Application logs show a repeating pattern of startup messages followed by a fatal error.\n",
      "\n",
      "## üìà Possible Causes\n",
      "- **Bad Configuration:** An environment variable is missing or malfo...\n",
      "\n",
      "2. Document: incident_004_crash_loop.json (Score/Distance: 1.0003)\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"alertName\": \"ServiceUnhealthy\",\n",
      "  \"source\": \"ECS\",\n",
      "  \"severity\": \"CRITICAL\",\n",
      "  \"timestamp\": \"2025-10-14T04:32:45Z\",\n",
      "  \"eventType\": \"ServiceDown\",\n",
      "  \"serviceName\": \"search-engine\",\n",
      "  \"clusterName\": \"opsflow-prod-cluster\",\n",
      "  \"reason\": \"Service has been restarting continuously.\",\n",
      "  \"details\": {\n",
      "    \"taskDefinition\": \"search-engine:v1.2.1\",\n",
      "    \"restartCount\": 6,\n",
      "    \"timeWindowMinutes\": 10,\n",
      "    \"lastError\": \"Container health check failed\"\n",
      "  }\n",
      "}...\n",
      "\n",
      "3. Document: memory_leak_recovery.md (Score/Distance: 1.3428)\n",
      "--------------------------------------------------\n",
      "# Memory Leak Recovery\n",
      "\n",
      "## üîç Incident Symptoms\n",
      "- The `eventType` is `ResourceExhaustion`.\n",
      "- The `memoryUsagePercent` metric for a service is steadily increasing over several hours and has now exceeded 95%.\n",
      "- The service may be experiencing performance degradation and increased garbage collection pauses.\n",
      "\n",
      "## üìà Possible Causes\n",
      "- **Code Defect:** An application bug is causing objects to be allocated but never released, leading to a gradual exhaustio...\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
